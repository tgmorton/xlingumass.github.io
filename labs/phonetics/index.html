<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Phonetics Lab | XLing Labs | UMass</title><meta name=keywords content="P-Lab"><meta name=description content="The Phonetics Laboratory provides state-of-the-art resources and tools for the study of the acoustics, perception, and neural representations of speech and other sounds.
The principal focus of our research is how listeners perceive speech, how their perception of speech is influenced by what they know about their language, and how their perception of speech might influence the phonology of their language. We also use electroencephalograpy to study the neural representations of speech sounds."><meta name=author content="Christian Muxica"><link rel=canonical href=https://xlingumass.github.io/labs/phonetics/><link crossorigin=anonymous href=/assets/css/stylesheet.min.a14de8fd347f2728f906ae18144f69aa1415f5160efef0209c1cca416aebedf0.css integrity="sha256-oU3o/TR/Jyj5Bq4YFE9pqhQV9RYO/vAgnBzKQWrr7fA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.umass.edu/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.umass.edu/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://www.umass.edu/favicon.ico><link rel=apple-touch-icon href=https://xlingumass.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://xlingumass.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Phonetics Lab"><meta property="og:description" content="The Phonetics Laboratory provides state-of-the-art resources and tools for the study of the acoustics, perception, and neural representations of speech and other sounds.
The principal focus of our research is how listeners perceive speech, how their perception of speech is influenced by what they know about their language, and how their perception of speech might influence the phonology of their language. We also use electroencephalograpy to study the neural representations of speech sounds."><meta property="og:type" content="article"><meta property="og:url" content="https://xlingumass.github.io/labs/phonetics/"><meta property="og:image" content="https://xlingumass.github.io/%3Cimage%20path/url%3E"><meta property="article:section" content="labs"><meta property="og:site_name" content="XLing Labs | UMass"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://xlingumass.github.io/%3Cimage%20path/url%3E"><meta name=twitter:title content="Phonetics Lab"><meta name=twitter:description content="The Phonetics Laboratory provides state-of-the-art resources and tools for the study of the acoustics, perception, and neural representations of speech and other sounds.
The principal focus of our research is how listeners perceive speech, how their perception of speech is influenced by what they know about their language, and how their perception of speech might influence the phonology of their language. We also use electroencephalograpy to study the neural representations of speech sounds."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Labs","item":"https://xlingumass.github.io/labs/"},{"@type":"ListItem","position":3,"name":"Phonetics Lab","item":"https://xlingumass.github.io/labs/phonetics/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Phonetics Lab","name":"Phonetics Lab","description":"The Phonetics Laboratory provides state-of-the-art resources and tools for the study of the acoustics, perception, and neural representations of speech and other sounds.\nThe principal focus of our research is how listeners perceive speech, how their perception of speech is influenced by what they know about their language, and how their perception of speech might influence the phonology of their language. We also use electroencephalograpy to study the neural representations of speech sounds.","keywords":["P-Lab"],"articleBody":"The Phonetics Laboratory provides state-of-the-art resources and tools for the study of the acoustics, perception, and neural representations of speech and other sounds.\nThe principal focus of our research is how listeners perceive speech, how their perception of speech is influenced by what they know about their language, and how their perception of speech might influence the phonology of their language. We also use electroencephalograpy to study the neural representations of speech sounds.\nA technique used in nearly all our studies is manipulating the context in which a target speech sound occurs to test hypotheses about how the target’s perception is influenced by that context. The context might make one percept of the target more likely than an alternative because that percept:\n Makes a word with the context, Is phonotactically legal in that context, Differs from or resembles that context,  but the alternative percept does none of these things.\nThe experiments use either categorization or discrimination tasks to test the effects of these manipulations of the target sound’s context.\nWe also use non-speech analogues, i.e., sounds that resemble speech sounds acoustically but which are not recognized as speech, to test the extent to which general rather than speech-specific mechanisms determine listeners’ percepts.\nFacilities The Phonetics Laboratory comprises four rooms in the Integrative Learning Center:\n N443: Four stations equipped with desktop computers, headphones, and button boxes where perception experiments are run, N445: An adjacent room from which the perception experiments are run using a desktop computer, N446: A room where EEG experiments are run, N448: A room with a single-walled, sound-attentuating booth for recording and digitizing directly to computer.  The computers in the N443 and N445 all run the Linux operating system. Experiments are run using PsychToolBox scripts. Other software includes Praat, R, RStudio, and Octave.\n","wordCount":"295","inLanguage":"en","image":"https://xlingumass.github.io/%3Cimage%20path/url%3E","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Christian Muxica"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://xlingumass.github.io/labs/phonetics/"},"publisher":{"@type":"Organization","name":"XLing Labs | UMass","logo":{"@type":"ImageObject","url":"https://www.umass.edu/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><script defer src=/static/fontawesome/fontawesome-all.js></script><header class=header><nav class=nav><div class=logo><a href=https://xlingumass.github.io accesskey=h title="XLing Labs (Alt + H)">XLing Labs</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://xlingumass.github.io/schedule/ title="Meeting Schedule"><span>Meeting Schedule</span></a></li><li><a href=https://xlingumass.github.io/labs/ title="Joint Labs"><span>Joint Labs</span></a></li><li><a href=https://xlingumass.github.io/docs/ title=Docs><span>Docs</span></a></li><li><a href=https://xlingumass.github.io/blog/ title=Blog><span>Blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://xlingumass.github.io>Home</a>&nbsp;»&nbsp;<a href=https://xlingumass.github.io/labs/>Labs</a></div><h1 class=post-title>Phonetics Lab</h1><div class=post-meta>Christian Muxica&nbsp;|&nbsp;<a href=https://github.com/xlingumass/xlingumass.github.io/content/labs/phonetics.md/labs/phonetics.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>The <a href=https://osf.io/jbvfr/>Phonetics Laboratory</a> provides state-of-the-art resources and tools for the study of the acoustics, perception, and neural representations of speech and other sounds.</p><p>The principal focus of our research is how listeners perceive speech, how their perception of speech is influenced by what they know about their language, and how their perception of speech might influence the phonology of their language. We also use electroencephalograpy to study the neural representations of speech sounds.</p><p>A technique used in nearly all our studies is manipulating the context in which a target speech sound occurs to test hypotheses about how the target&rsquo;s perception is influenced by that context. The context might make one percept of the target more likely than an alternative because that percept:</p><ul><li>Makes a word with the context,</li><li>Is phonotactically legal in that context,</li><li>Differs from or resembles that context,</li></ul><p>but the alternative percept does none of these things.</p><p>The experiments use either categorization or discrimination tasks to test the effects of these manipulations of the target sound&rsquo;s context.</p><p>We also use non-speech analogues, i.e., sounds that resemble speech sounds acoustically but which are not recognized as speech, to test the extent to which general rather than speech-specific mechanisms determine listeners&rsquo; percepts.</p><h2 id=facilities>Facilities<a hidden class=anchor aria-hidden=true href=#facilities>#</a></h2><p>The Phonetics Laboratory comprises four rooms in the Integrative Learning Center:</p><ol><li><strong>N443</strong>: Four stations equipped with desktop computers, headphones, and button boxes where perception experiments are run,</li><li><strong>N445</strong>: An adjacent room from which the perception experiments are run using a desktop computer,</li><li><strong>N446</strong>: A room where EEG experiments are run,</li><li><strong>N448</strong>: A room with a single-walled, sound-attentuating booth for recording and digitizing directly to computer.</li></ol><p>The computers in the N443 and N445 all run the Linux operating system. Experiments are run using <a href=http://psychtoolbox.org/>PsychToolBox</a> scripts. Other software includes <a href=http://www.fon.hum.uva.nl/praat/>Praat</a>, <a href=https://www.r-project.org/>R</a>, <a href=https://www.rstudio.com/>RStudio</a>, and <a href=https://www.gnu.org/software/octave/>Octave</a>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://xlingumass.github.io/tags/p-lab/>P-Lab</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://xlingumass.github.io>XLing Labs | UMass</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>